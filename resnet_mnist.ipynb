{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shatapy/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "                        tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(10000)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 10000)\n",
    "test_dataset = test_dataset.batch(batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                              train_dataset.output_types,\n",
    "                                              train_dataset.output_shapes)\n",
    "\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, tf.float32)\n",
    "y = tf.cast(y, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, output_channel, is_training=True, down_sampling=False, is_end=False):\n",
    "    \n",
    "    if down_sampling:\n",
    "        stride = 2\n",
    "    else:\n",
    "        stride = 1\n",
    "    \n",
    "    #  project shortcut? --> 1x1 convnet\n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d], weights_regularizer=slim.l2_regularizer(scale=.0003),\n",
    "                       normalizer_fn=slim.batch_norm,\n",
    "                       normalizer_params= {'decay': .9, 'is_training': is_training}):\n",
    "    \n",
    "        h1 = slim.conv2d(x, output_channel, [3, 3], stride=stride)\n",
    "        \n",
    "        h2 = slim.conv2d(h1, output_channel, [3, 3], activation_fn=None)\n",
    "\n",
    "    if down_sampling:\n",
    "        x = slim.conv2d(x, output_channel, [1, 1], stride=stride, activation_fn=None)\n",
    "    \n",
    "    if is_end:\n",
    "        return h2 + x\n",
    "    return tf.nn.relu(h2 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_resnet(x, layer_n):\n",
    "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    with tf.variable_scope('conv0'):\n",
    "        net = slim.conv2d(x, 16, [3, 3], activation_fn=None)\n",
    "        net = tf.layers.batch_normalization(net, epsilon=1e-5, training=is_training)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "    with tf.variable_scope('res0'):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(net, 16, is_training)\n",
    "    \n",
    "    with tf.variable_scope('res1'):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(net, 32, is_training, down_sampling=(i==0))\n",
    "            \n",
    "    with tf.variable_scope('res2'):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(net, 64, is_training, down_sampling=(i==0), is_end=(i==layer_n-1))\n",
    "            \n",
    "    with tf.variable_scope('fc'):\n",
    "        net = slim.flatten(net)\n",
    "        net = slim.fully_connected(net, 10, activation_fn=None)\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)\n",
    "logits = build_resnet(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=y)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', loss)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: graphs/resnet_mnist\n"
     ]
    }
   ],
   "source": [
    "graph_location = 'graphs/resnet_mnist'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "epochs = 3\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sess.run(train_iterator.initializer)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            _, loss_ = sess.run([train_op, loss], \n",
    "                                feed_dict={handle: train_handle, is_training: True})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(\"Step: %d, Loss: %g\" % (step, loss_))\n",
    "                \n",
    "                summary_str = sess.run(summary_op, \n",
    "                                      feed_dict={handle: train_handle, is_training: True})\n",
    "                train_writer.add_summary(summary_str, global_step=step)\n",
    "            \n",
    "            if step % 300 == 0:\n",
    "                print('Saving the model in ', graph_location)\n",
    "                saver.save(sess, graph_location + 'model.ckpt', global_step=step)\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of dataset')\n",
    "            break\n",
    "        \n",
    "    print('Epoch: ', epoch)\n",
    "\n",
    "train_writer.close()\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from graphs/resnet_mnistmodel.ckpt-1500\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = tf.train.latest_checkpoint('graphs/')\n",
    "saver.restore(sess, model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=y, predictions=tf.argmax(logits, 1), name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: test_handle, is_training: False})\n",
    "print(\"test accuracy:\", sess.run(accuracy, feed_dict={handle: test_handle, is_training: False}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
